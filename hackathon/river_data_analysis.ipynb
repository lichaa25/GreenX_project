{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2839f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m df = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33msimulated_river_data_with_anomalies.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m df.head()\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"simulated_river_data_with_anomalies.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a602a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp313-cp313-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.5 MB 4.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.6/11.5 MB 4.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.9/11.5 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.5 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.5/11.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 9.2/11.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.0/11.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.5/11.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 3.9 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 3.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/12.6 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.9/12.6 MB 4.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.7/12.6 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.8/12.6 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.6 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.8/12.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 7.9/12.6 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.4/12.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.0/12.6 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.6 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.6 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a79e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pH</th>\n",
       "      <th>turbidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>dissolved_oxygen</th>\n",
       "      <th>anomaly_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-30T23:15:08.198188</td>\n",
       "      <td>7.05</td>\n",
       "      <td>34.02</td>\n",
       "      <td>22.52</td>\n",
       "      <td>8.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-30T23:15:09.200297</td>\n",
       "      <td>7.42</td>\n",
       "      <td>129.51</td>\n",
       "      <td>23.84</td>\n",
       "      <td>9.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-05-30T23:15:10.203104</td>\n",
       "      <td>7.26</td>\n",
       "      <td>38.83</td>\n",
       "      <td>24.33</td>\n",
       "      <td>9.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-05-30T23:15:11.204273</td>\n",
       "      <td>4.85</td>\n",
       "      <td>35.24</td>\n",
       "      <td>15.24</td>\n",
       "      <td>8.01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-30T23:15:12.206261</td>\n",
       "      <td>7.77</td>\n",
       "      <td>38.59</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp    pH  turbidity  temperature  dissolved_oxygen  \\\n",
       "0  2025-05-30T23:15:08.198188  7.05      34.02        22.52              8.10   \n",
       "1  2025-05-30T23:15:09.200297  7.42     129.51        23.84              9.93   \n",
       "2  2025-05-30T23:15:10.203104  7.26      38.83        24.33              9.16   \n",
       "3  2025-05-30T23:15:11.204273  4.85      35.24        15.24              8.01   \n",
       "4  2025-05-30T23:15:12.206261  7.77      38.59        32.58              0.70   \n",
       "\n",
       "   anomaly_flag  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"simulated_river_data_with_anomalies.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf389a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   timestamp         20 non-null     object \n",
      " 1   pH                20 non-null     float64\n",
      " 2   turbidity         20 non-null     float64\n",
      " 3   temperature       20 non-null     float64\n",
      " 4   dissolved_oxygen  20 non-null     float64\n",
      " 5   anomaly_flag      20 non-null     int64  \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92dd5df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2444c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\asus\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp313-cp313-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 3.1 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.1 MB 3.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.1 MB 3.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.7/11.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.6/11.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.1 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.15.3-cp313-cp313-win_amd64.whl (41.0 MB)\n",
      "   ---------------------------------------- 0.0/41.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/41.0 MB 5.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.8/41.0 MB 4.4 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 2.4/41.0 MB 3.7 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.1/41.0 MB 3.7 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 3.7/41.0 MB 3.5 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 4.2/41.0 MB 3.4 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 5.0/41.0 MB 3.4 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 5.5/41.0 MB 3.4 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.3/41.0 MB 3.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 6.8/41.0 MB 3.3 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 7.6/41.0 MB 3.3 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 8.4/41.0 MB 3.3 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 9.2/41.0 MB 3.3 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 9.7/41.0 MB 3.3 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 10.5/41.0 MB 3.3 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 11.0/41.0 MB 3.3 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 11.3/41.0 MB 3.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 11.5/41.0 MB 3.2 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 11.8/41.0 MB 3.1 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 12.1/41.0 MB 3.0 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 12.6/41.0 MB 2.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 13.4/41.0 MB 2.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 13.9/41.0 MB 2.9 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 14.7/41.0 MB 2.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 15.5/41.0 MB 2.9 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 16.3/41.0 MB 2.9 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 16.8/41.0 MB 2.9 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 17.6/41.0 MB 3.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 18.4/41.0 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 19.1/41.0 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 19.7/41.0 MB 3.0 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 20.4/41.0 MB 3.0 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 21.2/41.0 MB 3.0 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 22.0/41.0 MB 3.0 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 22.8/41.0 MB 3.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 23.6/41.0 MB 3.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 24.4/41.0 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 25.2/41.0 MB 3.1 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 26.0/41.0 MB 3.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 26.7/41.0 MB 3.2 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 27.5/41.0 MB 3.2 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 28.0/41.0 MB 3.2 MB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 28.8/41.0 MB 3.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 29.6/41.0 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 30.4/41.0 MB 3.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 31.5/41.0 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 32.2/41.0 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 33.0/41.0 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 34.1/41.0 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 34.9/41.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 35.9/41.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 37.0/41.0 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 38.0/41.0 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.3/41.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.4/41.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/41.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.0/41.0 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1 scipy-1.15.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb803477",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\u001b[43mX\u001b[49m, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m      9\u001b[39m model = RandomForestClassifier()\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "438c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv('simulated_river_data_with_anomalies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec91cef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'pH', 'turbidity', 'temperature', 'dissolved_oxygen',\n",
      "       'anomaly_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e65ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"anomaly_flag\", axis=1)  \n",
    "y = df[\"anomaly_flag\"]               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafaa4bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2025-05-30T23:15:16.214989'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2320\\3740709344.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m      9\u001b[39m model = RandomForestClassifier()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model.fit(X_train, y_train)\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[32m     13\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1385\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m                 )\n\u001b[32m   1388\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    356\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    357\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    358\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    359\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         X, y = validate_data(\n\u001b[32m    361\u001b[39m             self,\n\u001b[32m    362\u001b[39m             X,\n\u001b[32m    363\u001b[39m             y,\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2957\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2958\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2959\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2962\u001b[39m         out = X, y\n\u001b[32m   2963\u001b[39m \n\u001b[32m   2964\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1366\u001b[39m         )\n\u001b[32m   1367\u001b[39m \n\u001b[32m   1368\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1369\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     X = check_array(\n\u001b[32m   1371\u001b[39m         X,\n\u001b[32m   1372\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1373\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1052\u001b[39m                         )\n\u001b[32m   1053\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1054\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1055\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1057\u001b[39m                 raise ValueError(\n\u001b[32m   1058\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1059\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    837\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    840\u001b[39m \n\u001b[32m    841\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    842\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2149\u001b[39m     def __array__(\n\u001b[32m   2150\u001b[39m         self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2151\u001b[39m     ) -> np.ndarray:\n\u001b[32m   2152\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m2153\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2154\u001b[39m         if (\n\u001b[32m   2155\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2156\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: '2025-05-30T23:15:16.214989'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4ca5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"simulated_river_data_with_anomalies.csv\")\n",
    "\n",
    "\n",
    "X = df.drop(\"anomaly_flag\", axis=1)\n",
    "y = df[\"anomaly_flag\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f076df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[[\"pH\", \"turbidity\", \"temperature\", \"dissolved_oxygen\"]]\n",
    "\n",
    "\n",
    "y = df[\"anomaly_flag\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b92c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.75      0.83      0.73         4\n",
      "weighted avg       0.88      0.75      0.77         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Results\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33b4837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# New data point\n",
    "new_data = [[6.5, 30.1, 22.3, 4.2]]  # pH, turbidity, temp, DO\n",
    "\n",
    "prediction = model.predict(new_data)\n",
    "print(\"Anomaly Detected!\" if prediction[0] == 1 else \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120e284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
